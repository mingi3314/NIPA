{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eda를 통해 x feature들의 값이 너무 skew한것을 보고, skew의 정도가 1 이상인 애들은 log1p를 씌어주면서 형식을 바꿔줬다.\n",
    "\n",
    "y의 값도 너무 skew하지만, 밑에 xgboost에서 objectvive를 포아송을 활용할거여서 괜찮다고 판단했다.\n",
    "(포아송 사용한 이유: y의 값이 ad_periods 기간이기에 사용함)\n",
    "\n",
    "xgboost모델을 사용하였는데, 이에 대한 최적의 파라미터는 grid search, optuna 등등을 사용하였지만,\n",
    "train과 valid로 나눴을때에서의 rmse성능을 비교해보면 bayesianOptimization이 가장 좋았다.\n",
    "\n",
    "그 결과 파라미터 자체는 이 값이 제일 높게 나왔고 이때 당시의 rmse는 train-rmse:19.51641\tvalid-rmse:30.88939 이렇게 나왔다. test_size를 0.01로 선정한 이유는 어차피, 밑에 코드에서 돌아갈때 cross validation이 있어 낮게 설정하였다.\n",
    "\n",
    "params = {} \n",
    "params['eta'] = 0.05 \n",
    "params['objective'] = 'count:poisson' \n",
    "params['eval_metric'] = 'rmse' \n",
    "#params['silent'] = 1 \n",
    "params['booster'] = 'gbtree' \n",
    "params['colsample_bytree'] = 0.7798 \n",
    "params['subsample'] = 0.76 \n",
    "params['max_depth'] = 6 \n",
    "params['min_child_weight'] = 3.833 \n",
    "params['gamma'] = 0.4928 \n",
    "params['alpha'] = 0.1171 \n",
    "params['lambda'] = 0.7742 \n",
    "params['grow_policy'] = 'lossguide' \n",
    "\n",
    "test set에서 데이터를 불러와 x feature들을 위와 같이 똑같은 형식으로 skew의 정도가 1 이상인 애들만 log1p를 씌어주고 위에서의 모델을 불러와 적용시켰다.\n",
    "\n",
    "추가적으로 본 차차차_last.ipnyb에도 마크다운 주석을 달아놔서 코드를 보면서 주석을 보면 이해하기가 한결 편할것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
